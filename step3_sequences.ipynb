{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: make your classifier\n",
    "\n",
    "### Background\n",
    "\n",
    "Transcription factors are proteins that bind DNA at promoters to drive gene expression. Most preferentially bind to specific sequences while ignoring others. Traditional methods to determine these sequences (called motifs) have assumed that binding sites in the genome are all independent. However, in some cases people have identified motifs where positional interdependencies exist.\n",
    "\n",
    "### Your task\n",
    "\n",
    "You will implement a multi-layer fully connected neural network using your NeuralNetwork class to predict whether a short DNA sequence is a binding site for the yeast transcription factor Rap1. The training data is incredibly imbalanced, with way fewer positive sequences than negative sequences, so you will implement a sampling scheme to ensure that class imbalance does not affect training. As in step 2, all of the following work should be done in a Jupyter Notebook.\n",
    "\n",
    "### To-do\n",
    "\n",
    " - Use the read_text_file function from io.py to read in the 137 positive Rap1 motif examples.\n",
    " - Use the read_fasta_file function from io.py to read in all the negative examples. Note that these sequences are much longer than the positive sequences, so you will need to process them to the same length.\n",
    " - Balance your classes using your sample_seq function and explain why you chose the sampling scheme you did.\n",
    " - One-hot encode the data using your one_hot_encode_seqs function.\n",
    " - Split the data into training and validation sets.\n",
    " - Generate an instance of your NeuralNetwork class with an appropriate architecture.\n",
    " - Train your neural network on the training data.\n",
    " - Plot your training and validation loss by epoch.\n",
    " - Report the accuracy of your classifier on your validation dataset.\n",
    " - Explain your choice of loss function and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from numpy.typing import ArrayLike\n",
    "from nn import io\n",
    "import re\n",
    "from collections import Counter\n",
    "from nn.nn import NeuralNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# timing function\n",
    "def display_run_time(s,e,task):\n",
    "    rt=(e-s)\n",
    "    if rt>=60:\n",
    "        rt=rt/60\n",
    "        print(f\"{task}: {rt} m\")\n",
    "    else:\n",
    "        print(f\"{task}: {rt} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
